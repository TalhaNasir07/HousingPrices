# -*- coding: utf-8 -*-
"""Columns_done_final_(1) (1) (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NSU0FOJrHMFLHvxjomPRu8g4a5kVJffD
"""

import numpy as np
import pandas as pd

df_test = pd.read_csv('train.csv')
df_test.head()

"""# New section"""

#checking for null values in each column
df_test.isnull().sum()

df_test.shape

df_test.info()

#To ensure uniformity in column names, We removed all spaces at the end(if any existed) and also set names to lowercase
df_test.columns= df_test.columns.str.strip().str.lower() 
df_test.head()

#need to replace the value '-' with 0 in bath and bedroom columns
df_test["baths"] = df_test["baths"].replace(['-'],[0])
df_test["bedroom(s)"] = df_test["bedroom(s)"].replace(['-'],[0])

def areaRegulator(area_col):
    real_area = []
    for each in area_col:
        each=each.split(' ')
        if 'Kanal' in each:
            real_area.append(float(each[0])*20)
        elif 'Marla' in each:
            real_area.append(float(each[0]))
        else:
            print(each)
    return np.array(real_area,'float64')
    
res = areaRegulator(df_test['area'])

def featureExtractor(area_col):
    unique_features = {}
    for each in area_col:
        each = each.split(',')
        each = [feature.strip() for feature in each]
        each = [ feature.split(':') for feature in each]
        each = [ [feature.strip().lower() for feature in features] for features in each]
        for features in each:
            if features[0] not in unique_features:
                if len(features) > 1:
                    unique_features[features[0]] = 'int'
                else:
                    unique_features[features[0]] = 'disc'
            elif len(features) > 1 and unique_features[features[0]]=='disc':
                unique_features[features[0]] = 'int'
            elif len(features) > 2:
                print(features)
    if '' in unique_features:
        del unique_features['']
    return unique_features

def sourceExtractor(source_col):
    sources = {'islamabad':[] , 'lahore':[] , 'karachi':[] }
    counter = 0
    for each in source_col:
        each = each.split('-')
        example ={each[0].lower():1}
        for each_loc in sources:
            if each_loc not in example:
                sources[each_loc].append(0)
            else:
                sources[each_loc].append(1)
    return sources

def mainExtractor(main_col):
    total_features = featureExtractor(main_col)
    new_features = {each:[] for each in total_features}
    for each_desc in main_col:
        each_desc = each_desc.split(',')
        each_desc = [ each.strip() for each in each_desc]
        each_desc = [each.split(':') for each in each_desc]
        each_desc = [ [each.strip().lower() for each in features] for features in each_desc]
        example = {}
        for each_feature in each_desc:
            if len(each_feature)>1:
                example[each_feature[0]] = float(each_feature[1].strip())
            else:
                example[each_feature[0]] = 1
        for each_feature in total_features:
            if each_feature not in example:
                new_features[each_feature].append(0)
            else:
                new_features[each_feature].append(example[each_feature])
    return new_features

res = sourceExtractor(df_test['source'])

sources = {'islamabad':[] , 'lahore':[] , 'karachi':[] }
counter = 0
for each in df_test["source"]:
    each = each.split('-')
    example ={each[0].lower():1}
    for each_loc in sources:
        if each_loc not in example:
            sources[each_loc].append(0)
        else:
            sources[each_loc].append(1)

cities=pd.DataFrame(sources)
cities

Final_Draframe=df_test
Final_Draframe=pd.concat([pd.DataFrame(sourceExtractor(df_test['source'])), Final_Draframe],axis=1)

#Fixing area - (Marla/Kanal) issue
b_df=pd.DataFrame(areaRegulator(df_test["area"]))
Final_Draframe=pd.concat([b_df, Final_Draframe],axis=1)
Final_Draframe=Final_Draframe.rename(columns={0: 'area (Marla)'})

#Splitting business and communication column into seperate columns
c_df=pd.DataFrame(mainExtractor(Final_Draframe["business and communication"]))
Final_Draframe=pd.concat([c_df, Final_Draframe],axis=1)

#Splitting nearby locations and other facilities column into seperate columns
d_df=pd.DataFrame(mainExtractor(Final_Draframe["nearby locations and other facilities"]))
Final_Draframe=pd.concat([d_df, Final_Draframe],axis=1)

#Splitting healthcare recreationals column into seperate columns
e_df=pd.DataFrame(mainExtractor(Final_Draframe["healthcare recreational"]))
Final_Draframe=pd.concat([e_df, Final_Draframe],axis=1)

#Splitting other facilities column into seperate columns
f_df=pd.DataFrame(mainExtractor(Final_Draframe["other facilities"]))
Final_Draframe=pd.concat([f_df, Final_Draframe],axis=1)

#Splitting rooms column into seperate columns
h_df=pd.DataFrame(mainExtractor(Final_Draframe["rooms"]))
Final_Draframe=pd.concat([h_df, Final_Draframe],axis=1)

#Splitting main features column into seperate columns
g_df=pd.DataFrame(mainExtractor(Final_Draframe["main features"]))
Final_Draframe=pd.concat([g_df, Final_Draframe],axis=1)

#dropping some more useless columns
Final_Draframe.drop("business and communication", axis=1,inplace=True)
Final_Draframe.drop("healthcare recreational", axis=1,inplace=True)
Final_Draframe.drop("nearby locations and other facilities", axis=1,inplace=True)
Final_Draframe.drop("other facilities", axis=1,inplace=True)
Final_Draframe.drop("main features", axis=1,inplace=True)
Final_Draframe.drop("rooms", axis=1,inplace=True)
Final_Draframe.drop("area", axis=1,inplace=True)
Final_Draframe.drop("bathrooms", axis=1,inplace=True)
Final_Draframe.drop("bedroom(s)", axis=1,inplace=True)

Final_Draframe.drop("type", axis=1,inplace=True)
Final_Draframe.drop("purpose", axis=1,inplace=True)
Final_Draframe.drop("description", axis=1,inplace=True)
Final_Draframe.drop("title", axis=1,inplace=True)
Final_Draframe.drop("time stamp", axis=1,inplace=True)
Final_Draframe.drop("property_id", axis=1,inplace=True)

Final_Draframe['floors'] = Final_Draframe['floors'].replace([0.0],[1.0])

Final_Draframe.columns

#To ensure uniformity in column names once again, We removed all spaces at the end(if any existed) and also set names to lowercase
Final_Draframe.columns= Final_Draframe.columns.str.strip().str.lower()

Final_Draframe.drop("source", axis=1,inplace=True)
Final_Draframe.drop("label", axis=1,inplace=True)
Final_Draframe.drop("popular", axis=1,inplace=True)
Final_Draframe.drop("location", axis=1,inplace=True)

Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(0,np.nan)
#Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(np.nan,0)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(21017,2017)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(20184,2018)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(20108,2018)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(2109,2019)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(2048,2018)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(1,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(9,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(10,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(15,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(20,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(240,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(300,np.nan)
Final_Draframe["built in year"]=Final_Draframe["built in year"].replace(np.nan,np.mean(Final_Draframe['built in year']))

Final_Draframe['built in year'].unique()

Final_Draframe.columns

#Final Data cleaning

    # dropping the following columns since >98% of the values are 0
Final_Draframe.drop("communal/shared kitchen", axis=1,inplace=True) 
Final_Draframe.drop("cctv security", axis=1,inplace=True) 
Final_Draframe.drop("cafeteria/canteen", axis=1,inplace=True) 
Final_Draframe.drop("atm machines", axis=1,inplace=True) 
Final_Draframe.drop("conference room in building", axis=1,inplace=True) 
Final_Draframe.drop("business center or media room in building", axis=1,inplace=True) 
Final_Draframe.drop("service elevators in building", axis=1,inplace=True)
Final_Draframe.drop("elevator or lift", axis=1,inplace=True)
Final_Draframe.drop("underground parking", axis=1,inplace=True)
Final_Draframe.drop("lobby in building", axis=1,inplace=True)
Final_Draframe.drop("public parking", axis=1,inplace=True)

    # Fixing outliers and replacing 0 values in columns with unreasonably high number of 0s
    
#Parking Spaces
Final_Draframe.sort_values(["parking spaces"],ascending=False)
Final_Draframe["parking spaces"].value_counts()
#setting a maximum range of 8
Final_Draframe["parking spaces"] = Final_Draframe["parking spaces"].replace([53,15,10,18,20],0)
#Replacing overwhelming number of 0 values with mean
Final_Draframe["parking spaces"]=Final_Draframe["parking spaces"].replace(0, np.nan) #First set 0 values to nan to find out true mean
Final_Draframe["parking spaces"].value_counts()
Final_Draframe["parking spaces"].describe()
Final_Draframe["parking spaces"] = Final_Draframe["parking spaces"].replace(np.nan, 2.230066)


#Floors
Final_Draframe["floors"].value_counts()
Final_Draframe["floors"]=Final_Draframe["floors"].replace(0, np.nan) #First set 0 values to nan to find out true mean
Final_Draframe["floors"].describe()
Final_Draframe["floors"] = Final_Draframe["floors"].replace(np.nan, 1.927226)


#baths
Final_Draframe['baths'].astype(float)
Final_Draframe["baths"].value_counts()
#Final_Draframe.sort_values(["baths"],ascending=False)
Final_Draframe["baths"]=Final_Draframe["baths"].replace(0, np.nan) #First set 0 values to nan to find out true mean
Final_Draframe["baths"].value_counts()
Final_Draframe["baths"] = Final_Draframe["baths"].replace([13,14,15,18,41],0)
Final_Draframe["baths"].describe()
Final_Draframe["baths"] = Final_Draframe["baths"].replace(np.nan, 5.151015)


#servant quarters
Final_Draframe["servant quarters"].value_counts()
Final_Draframe.sort_values(["servant quarters"],ascending=False)
Final_Draframe["servant quarters"] = Final_Draframe["servant quarters"].replace([22],0)
Final_Draframe["servant quarters"].describe()
Final_Draframe["servant quarters"]=Final_Draframe["servant quarters"].replace(0, np.nan) #First set 0 values to nan to find out true mean
Final_Draframe["servant quarters"].describe()
Final_Draframe["servant quarters"] = Final_Draframe["servant quarters"].replace(np.nan, 1.284900)


#Kitchens
Final_Draframe["kitchens"].value_counts()
Final_Draframe["kitchens"] = Final_Draframe["kitchens"].replace([21,22],0)
Final_Draframe["kitchens"]=Final_Draframe["kitchens"].replace(0, np.nan)
Final_Draframe["kitchens"].describe()
Final_Draframe["kitchens"] = Final_Draframe["kitchens"].replace(np.nan, 1.651142)


#store rooms
Final_Draframe["store rooms"].value_counts()
Final_Draframe["store rooms"]=Final_Draframe["store rooms"].replace(0, np.nan)
Final_Draframe["store rooms"].describe()
Final_Draframe["store rooms"] = Final_Draframe["store rooms"].replace(np.nan, 1.198773)

#bedrooms
Final_Draframe["bedrooms"].value_counts()
Final_Draframe["bedrooms"]=Final_Draframe["bedrooms"].replace(0, np.nan) #First set 0 values to nan to find out true mean
Final_Draframe["bedrooms"].describe()
Final_Draframe["bedrooms"] = Final_Draframe["bedrooms"].replace(np.nan, 4.551974)

Final_Draframe.columns

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix 
from sklearn.neural_network import MLPClassifier as classifier
from sklearn.model_selection import GridSearchCV
import tensorflow as tf
from tensorflow import keras
from sklearn.model_selection import train_test_split

x_train = Final_Draframe.loc[:, :'baths']
y_train = Final_Draframe['price_category']
print(y_train)

x_train['baths'] = x_train['baths'].astype(float)
x_train.dtypes

def tokeniser(labels):
    label_mappings = {}
    counter=0
    total_labels = labels.unique()
    for each in total_labels:
        label_mappings[each] = counter
        counter+=1
    new_labels = []
    for each in labels:
        new_labels.append(label_mappings[each])
    return label_mappings,np.array(new_labels,'int32')


def normaliser(training_data):
    for each in training_data:
        if len(training_data[each].unique()) != 2:
            x = training_data[each]
            x-= np.mean(x)
            x/= np.std(x)
            training_data[each] = x
    return training_data

x_train_normalised = normaliser(x_train)
label_mappings , y_train = tokeniser(y_train)
y_train_categorical = keras.utils.to_categorical(y_train)

y_train_categorical[:5]

lr_init=[0.4,0.1,0.08,0.08,0.08,0.06,0.03,0.02]
layer_sizes=[(64,32,16,8),(128,64,32),(64,32,16),(128,64),(32,32,8),(32,16,8),(32,16),(64),(64, 32),(32),(16,8),(16,8,4)]
parameters={'learning_rate_init':lr_init,'hidden_layer_sizes':layer_sizes}

model = classifier(random_state=1,activation='logistic',solver='adam',max_iter=6000, learning_rate_init=0.01,hidden_layer_sizes=(128,64,32,16,8), verbose =2, tol = 1e-10, n_iter_no_change= 3000, validation_fraction = 0.1)

x_train,x_test,y_train,y_test = train_test_split(x_train_normalised,y_train_categorical,test_size=0.2 , random_state=42)

print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)

model.fit(x_train,y_train)

y_true= np.argmax(y_test, axis=1).reshape((-1,1))
y_real = model.predict(x_test)
y_pred=np.argmax(y_real,axis=1)
accuracy = accuracy_score(np.ravel(y_true), np.ravel(y_pred))
perf_metrics =classification_report(y_true,y_pred,output_dict=False)
print(perf_metrics)